{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dataclasses-json\n",
        "!pip install supervision"
      ],
      "metadata": {
        "id": "Vn43w59gJ1iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YZBGd3PUZzY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Union, Optional\n",
        "from dataclasses_json import dataclass_json\n",
        "from supervision import Detections\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOCategory:\n",
        "    id: int\n",
        "    name: str\n",
        "    supercategory: str\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOImage:\n",
        "    id: int\n",
        "    width: int\n",
        "    height: int\n",
        "    file_name: str\n",
        "    license: int\n",
        "    date_captured: str\n",
        "    coco_url: Optional[str] = None\n",
        "    flickr_url: Optional[str] = None\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOAnnotation:\n",
        "    id: int\n",
        "    image_id: int\n",
        "    category_id: int\n",
        "    segmentation: List[List[float]]\n",
        "    area: float\n",
        "    bbox: Tuple[float, float, float, float]\n",
        "    iscrowd: int\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOLicense:\n",
        "    id: int\n",
        "    name: str\n",
        "    url: str\n",
        "\n",
        "\n",
        "@dataclass_json\n",
        "@dataclass\n",
        "class COCOJson:\n",
        "    images: List[COCOImage]\n",
        "    annotations: List[COCOAnnotation]\n",
        "    categories: List[COCOCategory]\n",
        "    licenses: List[COCOLicense]\n",
        "\n",
        "\n",
        "def load_coco_json(json_file: str) -> COCOJson:\n",
        "    import json\n",
        "\n",
        "    with open(json_file, \"r\") as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    return COCOJson.from_dict(json_data)\n",
        "\n",
        "\n",
        "class COCOJsonUtility:\n",
        "    @staticmethod\n",
        "    def get_annotations_by_image_id(coco_data: COCOJson, image_id: int) -> List[COCOAnnotation]:\n",
        "        return [annotation for annotation in coco_data.annotations if annotation.image_id == image_id]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_annotations_by_image_path(coco_data: COCOJson, image_path: str) -> Optional[List[COCOAnnotation]]:\n",
        "        image = COCOJsonUtility.get_image_by_path(coco_data, image_path)\n",
        "        if image:\n",
        "            return COCOJsonUtility.get_annotations_by_image_id(coco_data, image.id)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def get_image_by_path(coco_data: COCOJson, image_path: str) -> Optional[COCOImage]:\n",
        "        for image in coco_data.images:\n",
        "            if image.file_name == image_path:\n",
        "                return image\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def annotations2detections(annotations: List[COCOAnnotation]) -> Detections:\n",
        "        class_id, xyxy = [], []\n",
        "\n",
        "        for annotation in annotations:\n",
        "            x_min, y_min, width, height = annotation.bbox\n",
        "            class_id.append(annotation.category_id)\n",
        "            xyxy.append([\n",
        "                x_min,\n",
        "                y_min,\n",
        "                x_min + width,\n",
        "                y_min + height\n",
        "            ])\n",
        "\n",
        "        return Detections(\n",
        "            xyxy=np.array(xyxy, dtype=int),\n",
        "            class_id=np.array(class_id, dtype=int)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow"
      ],
      "metadata": {
        "id": "WQleS6P8Kwh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "import roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "rf = Roboflow()\n",
        "\n",
        "project = rf.workspace(\"hashira-fhxpj\").project(\"mri-brain-tumor\")\n",
        "dataset = project.version(1).download(\"coco\")"
      ],
      "metadata": {
        "id": "fEEYMAcRJp1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_SET_SUBDIRECTORY = \"test\"\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\"\n",
        "IMAGES_DIRECTORY_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY)\n",
        "ANNOTATIONS_FILE_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY, ANNOTATIONS_FILE_NAME)"
      ],
      "metadata": {
        "id": "u5u0oSlLKrfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco_data = load_coco_json(json_file=ANNOTATIONS_FILE_PATH)\n",
        "\n",
        "CLASSES = [\n",
        "    category.name\n",
        "    for category\n",
        "    in coco_data.categories\n",
        "    if category.supercategory != 'none'\n",
        "]\n",
        "\n",
        "IMAGES = [\n",
        "    image.file_name\n",
        "    for image\n",
        "    in coco_data.images\n",
        "]"
      ],
      "metadata": {
        "id": "TwHZG10yMKYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES"
      ],
      "metadata": {
        "id": "Vh3YBk6qNsnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(10)"
      ],
      "metadata": {
        "id": "gQzu-OqHNv7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'"
      ],
      "metadata": {
        "id": "yWlbwkp2R5YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision==0.23.0"
      ],
      "metadata": {
        "id": "8aElGNglS1if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {HOME}/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {HOME}/weights"
      ],
      "metadata": {
        "id": "irlINCfvS3Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
      ],
      "metadata": {
        "id": "Eir0LvU7S5Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\""
      ],
      "metadata": {
        "id": "c0H3SSirS6rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
      ],
      "metadata": {
        "id": "XjVqbuGIS-3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "mask_predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "q4Otw38WS_RP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "\n",
        "\n",
        "EXAMPLE_IMAGE_NAME = random.choice(IMAGES)\n",
        "EXAMPLE_IMAGE_PATH = os.path.join(dataset.location, DATA_SET_SUBDIRECTORY, EXAMPLE_IMAGE_NAME)\n",
        "\n",
        "# load dataset annotations\n",
        "annotations = COCOJsonUtility.get_annotations_by_image_path(coco_data=coco_data, image_path=EXAMPLE_IMAGE_NAME)\n",
        "ground_truth = COCOJsonUtility.annotations2detections(annotations=annotations)\n",
        "\n",
        "# small hack - coco numerate classes from 1, model from 0 + we drop first redundant class from coco json\n",
        "ground_truth.class_id = ground_truth.class_id - 1\n",
        "\n",
        "# load image\n",
        "image_bgr = cv2.imread(EXAMPLE_IMAGE_PATH)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# initiate annotator\n",
        "box_annotator = sv.BoxAnnotator(color=sv.Color.RED, color_lookup=sv.ColorLookup.INDEX)\n",
        "mask_annotator = sv.MaskAnnotator(color=sv.Color.RED, color_lookup=sv.ColorLookup.INDEX)\n",
        "\n",
        "# annotate ground truth\n",
        "annotated_frame_ground_truth = box_annotator.annotate(scene=image_bgr.copy(), detections=ground_truth)\n",
        "\n",
        "# run SAM inference\n",
        "mask_predictor.set_image(image_rgb)\n",
        "\n",
        "masks, scores, logits = mask_predictor.predict(\n",
        "    box=ground_truth.xyxy[0],\n",
        "    multimask_output=True\n",
        ")\n",
        "\n",
        "detections = sv.Detections(\n",
        "    xyxy=sv.mask_to_xyxy(masks=masks),\n",
        "    mask=masks\n",
        ")\n",
        "detections = detections[detections.area == np.max(detections.area)]\n",
        "\n",
        "annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=[annotated_frame_ground_truth, annotated_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['source image', 'segmented image']\n",
        ")"
      ],
      "metadata": {
        "id": "oJBLnMojN7DY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}